pipeline {
    agent any

    environment {
        ENVIRONMENT = 'production'
        BRANCH_UAT = 'main'
        S3_CREDENTIAL = 'S3'
        S3_REGION = 'ap-southeast-2'
        BUCKET_NAME = 's3://chaokai.me2'
        WORKSPACE_PATH = '/var/lib/jenkins/workspace/devops-frontend' 
    }

    options {
        // Keep maximum 10 archieved artifacts
        buildDiscarder(logRotator(numToKeepStr:'10', artifactNumToKeepStr:'10'))
        // No simultaneous builds
        disableConcurrentBuilds()
        durabilityHint('PERFORMANCE_OPTIMIZED') //MAX_SURVIVABILITY or SURVIVABLE_NONATOMIC
    }

    stages {
        stage('Git checkout') {
            steps{
                // Get source code from a GitHub repository
                git branch:'main', url:'https://github.com/KaysenLai/devops-frontend'
            }
        }
        stage('Install packages') {
            steps {
                echo "Installing packages ..."
                sh "node -v"
                //Install the packages from package.json
                sh 'npm install'
            }
        }
        stage('Build') {
            agent {
                docker {
                    image 'node:14.15.0'
                    args '-e npm_config_cache=npm-cache -e HOME=.'
                }
            }
            steps {
                echo "Building ..."
                echo "Running job: ${env.JOB_NAME}\n Build: ${env.BUILD_ID} - ${env.BUILD_URL}\nPepeline: ${env.RUN_DISPLAY_URL}"
                sh 'npm run build'
            }
        }

        // stage('Deploy to UAT') {
        //     when {
        //         expression { currentBuild.result == null || currentBuild.result == 'SUCCESS' }
        //     }
        //     steps {
        //         deployToS3(ENVIRONMENT)
        //     }
        // }
    }

    post {
        success {
            echo "WELL DONE!!"
        }
        failure {
            echo "FAILED"
        }
    }
}

def deployToS3(environment) {
    echo 'Deploying to ' + environment + ' ...'
    withAWS(credentials: S3_CREDENTIAL, region: S3_REGION) {
        // Empty the UAT bucket
        sh 'aws s3 rm "${BUCKET_NAME}" --recursive'
        // Copy the static files from workspace to the S3 bucket
        sh 'aws s3 cp "${WORKSPACE_PATH}" "${BUCKET_NAME}" --recursive --acl public-read'
    }
}

